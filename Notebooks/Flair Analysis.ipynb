{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../preds/classifier_needadvice_bert_dropout:0.1_lr_tr:1e-05_lr_cl:1e-05_wd:0_batch:32_finetune:True_query:False_context:False_seed:20_multigpu:True_labels:ds_frac:1.csv', header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Education': 173,\n",
       "         'Mental Health': 314,\n",
       "         'Life Decisions': 194,\n",
       "         'Friendships': 118,\n",
       "         'Career': 17})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df['Flair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0, 1]\n",
    "target_names = ['0', '1']\n",
    "sigdig=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8424    0.8579    0.8501       542\n",
      "           1     0.7083    0.6825    0.6952       274\n",
      "\n",
      "    accuracy                         0.7990       816\n",
      "   macro avg     0.7754    0.7702    0.7726       816\n",
      "weighted avg     0.7974    0.7990    0.7981       816\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_labels = df['DS_Label'].values\n",
    "pred_labels = df['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friendships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9176    0.8966    0.9070        87\n",
      "           1     0.7273    0.7742    0.7500        31\n",
      "\n",
      "    accuracy                         0.8644       118\n",
      "   macro avg     0.8225    0.8354    0.8285       118\n",
      "weighted avg     0.8676    0.8644    0.8657       118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_friend = df[df['Flair']=='Friendships']\n",
    "target_labels = df_friend['DS_Label'].values\n",
    "pred_labels = df_friend['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mental Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8348    0.8863    0.8598       211\n",
      "           1     0.7333    0.6408    0.6839       103\n",
      "\n",
      "    accuracy                         0.8057       314\n",
      "   macro avg     0.7841    0.7635    0.7719       314\n",
      "weighted avg     0.8015    0.8057    0.8021       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_mental = df[df['Flair']=='Mental Health']\n",
    "target_labels = df_mental['DS_Label'].values\n",
    "pred_labels = df_mental['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8051    0.8190    0.8120       116\n",
      "           1     0.6182    0.5965    0.6071        57\n",
      "\n",
      "    accuracy                         0.7457       173\n",
      "   macro avg     0.7116    0.7077    0.7096       173\n",
      "weighted avg     0.7435    0.7457    0.7445       173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_edu = df[df['Flair']=='Education']\n",
    "target_labels = df_edu['DS_Label'].values\n",
    "pred_labels = df_edu['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Career"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6364    0.8750    0.7368         8\n",
      "           1     0.8333    0.5556    0.6667         9\n",
      "\n",
      "    accuracy                         0.7059        17\n",
      "   macro avg     0.7348    0.7153    0.7018        17\n",
      "weighted avg     0.7406    0.7059    0.6997        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_career = df[df['Flair']=='Career']\n",
    "target_labels = df_career['DS_Label'].values\n",
    "pred_labels = df_career['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Life Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8596    0.8167    0.8376       120\n",
      "           1     0.7250    0.7838    0.7532        74\n",
      "\n",
      "    accuracy                         0.8041       194\n",
      "   macro avg     0.7923    0.8002    0.7954       194\n",
      "weighted avg     0.8083    0.8041    0.8054       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_lf = df[df['Flair']=='Life Decisions']\n",
    "target_labels = df_lf['DS_Label'].values\n",
    "pred_labels = df_lf['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../../preds/test/classifier_needadvice_bert_dropout:0.1_lr_tr:1e-05_lr_cl:1e-05_wd:0_batch:32_finetune:True_query:False_context:False_seed:2_multigpu:True_labels:ds_frac:1_TEST.csv', header=0, sep='\\t')\n",
    "df13 = pd.read_csv('../../preds/test/classifier_needadvice_bert_dropout:0.1_lr_tr:1e-05_lr_cl:1e-05_wd:0_batch:32_finetune:True_query:False_context:False_seed:13_multigpu:True_labels:ds_frac:1_TEST.csv', header=0, sep='\\t')\n",
    "df20 = pd.read_csv('../../preds/test/classifier_needadvice_bert_dropout:0.1_lr_tr:1e-05_lr_cl:1e-05_wd:0_batch:32_finetune:True_query:False_context:False_seed:20_multigpu:True_labels:ds_frac:1_TEST.csv', header=0, sep='\\t')\n",
    "df45 = pd.read_csv('../../preds/test/classifier_needadvice_bert_dropout:0.1_lr_tr:1e-05_lr_cl:1e-05_wd:0_batch:32_finetune:True_query:False_context:False_seed:45_multigpu:True_labels:ds_frac:1_TEST.csv', header=0, sep='\\t')\n",
    "df78 = pd.read_csv('../../preds/test/classifier_needadvice_bert_dropout:0.1_lr_tr:1e-05_lr_cl:1e-05_wd:0_batch:32_finetune:True_query:False_context:False_seed:78_multigpu:True_labels:ds_frac:1_TEST.csv', header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friendships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9783    0.9375    0.9574        48\n",
      "           1     0.8333    0.9375    0.8824        16\n",
      "\n",
      "    accuracy                         0.9375        64\n",
      "   macro avg     0.9058    0.9375    0.9199        64\n",
      "weighted avg     0.9420    0.9375    0.9387        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_friend = df2[df2['Flair']=='Friendships']\n",
    "target_labels = df2_friend['DS_Label'].values\n",
    "pred_labels = df2_friend['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9778    0.9167    0.9462        48\n",
      "           1     0.7895    0.9375    0.8571        16\n",
      "\n",
      "    accuracy                         0.9219        64\n",
      "   macro avg     0.8836    0.9271    0.9017        64\n",
      "weighted avg     0.9307    0.9219    0.9240        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df13_friend = df13[df13['Flair']=='Friendships']\n",
    "target_labels = df13_friend['DS_Label'].values\n",
    "pred_labels = df13_friend['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9792    0.9792    0.9792        48\n",
      "           1     0.9375    0.9375    0.9375        16\n",
      "\n",
      "    accuracy                         0.9688        64\n",
      "   macro avg     0.9583    0.9583    0.9583        64\n",
      "weighted avg     0.9688    0.9688    0.9688        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df20_friend = df20[df20['Flair']=='Friendships']\n",
    "target_labels = df20_friend['DS_Label'].values\n",
    "pred_labels = df20_friend['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9783    0.9375    0.9574        48\n",
      "           1     0.8333    0.9375    0.8824        16\n",
      "\n",
      "    accuracy                         0.9375        64\n",
      "   macro avg     0.9058    0.9375    0.9199        64\n",
      "weighted avg     0.9420    0.9375    0.9387        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df45_friend = df45[df45['Flair']=='Friendships']\n",
    "target_labels = df45_friend['DS_Label'].values\n",
    "pred_labels = df45_friend['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9787    0.9583    0.9684        48\n",
      "           1     0.8824    0.9375    0.9091        16\n",
      "\n",
      "    accuracy                         0.9531        64\n",
      "   macro avg     0.9305    0.9479    0.9388        64\n",
      "weighted avg     0.9546    0.9531    0.9536        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df78_friend = df78[df78['Flair']=='Friendships']\n",
    "target_labels = df78_friend['DS_Label'].values\n",
    "pred_labels = df78_friend['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mental Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8741    0.8065    0.8389       155\n",
      "           1     0.7059    0.8000    0.7500        90\n",
      "\n",
      "    accuracy                         0.8041       245\n",
      "   macro avg     0.7900    0.8032    0.7945       245\n",
      "weighted avg     0.8123    0.8041    0.8063       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_mental = df2[df2['Flair']=='Mental Health']\n",
    "target_labels = df2_mental['DS_Label'].values\n",
    "pred_labels = df2_mental['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8500    0.8774    0.8635       155\n",
      "           1     0.7765    0.7333    0.7543        90\n",
      "\n",
      "    accuracy                         0.8245       245\n",
      "   macro avg     0.8132    0.8054    0.8089       245\n",
      "weighted avg     0.8230    0.8245    0.8234       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df13_mental = df13[df13['Flair']=='Mental Health']\n",
    "target_labels = df13_mental['DS_Label'].values\n",
    "pred_labels = df13_mental['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8395    0.8774    0.8580       155\n",
      "           1     0.7711    0.7111    0.7399        90\n",
      "\n",
      "    accuracy                         0.8163       245\n",
      "   macro avg     0.8053    0.7943    0.7990       245\n",
      "weighted avg     0.8144    0.8163    0.8146       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df20_mental = df20[df20['Flair']=='Mental Health']\n",
    "target_labels = df20_mental['DS_Label'].values\n",
    "pred_labels = df20_mental['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8609    0.8387    0.8497       155\n",
      "           1     0.7340    0.7667    0.7500        90\n",
      "\n",
      "    accuracy                         0.8122       245\n",
      "   macro avg     0.7975    0.8027    0.7998       245\n",
      "weighted avg     0.8143    0.8122    0.8131       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df45_mental = df45[df45['Flair']=='Mental Health']\n",
    "target_labels = df45_mental['DS_Label'].values\n",
    "pred_labels = df45_mental['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8466    0.8903    0.8679       155\n",
      "           1     0.7927    0.7222    0.7558        90\n",
      "\n",
      "    accuracy                         0.8286       245\n",
      "   macro avg     0.8197    0.8063    0.8119       245\n",
      "weighted avg     0.8268    0.8286    0.8267       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df78_mental = df78[df78['Flair']=='Mental Health']\n",
    "target_labels = df78_mental['DS_Label'].values\n",
    "pred_labels = df78_mental['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7553    0.8659    0.8068        82\n",
      "           1     0.8333    0.7051    0.7639        78\n",
      "\n",
      "    accuracy                         0.7875       160\n",
      "   macro avg     0.7943    0.7855    0.7854       160\n",
      "weighted avg     0.7934    0.7875    0.7859       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_edu = df2[df2['Flair']=='Education']\n",
    "target_labels = df2_edu['DS_Label'].values\n",
    "pred_labels = df2_edu['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7604    0.8902    0.8202        82\n",
      "           1     0.8594    0.7051    0.7746        78\n",
      "\n",
      "    accuracy                         0.8000       160\n",
      "   macro avg     0.8099    0.7977    0.7974       160\n",
      "weighted avg     0.8087    0.8000    0.7980       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df13_edu = df13[df13['Flair']=='Education']\n",
    "target_labels = df13_edu['DS_Label'].values\n",
    "pred_labels = df13_edu['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7103    0.9268    0.8042        82\n",
      "           1     0.8868    0.6026    0.7176        78\n",
      "\n",
      "    accuracy                         0.7688       160\n",
      "   macro avg     0.7985    0.7647    0.7609       160\n",
      "weighted avg     0.7963    0.7688    0.7620       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df20_edu = df20[df20['Flair']=='Education']\n",
    "target_labels = df20_edu['DS_Label'].values\n",
    "pred_labels = df20_edu['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7826    0.8780    0.8276        82\n",
      "           1     0.8529    0.7436    0.7945        78\n",
      "\n",
      "    accuracy                         0.8125       160\n",
      "   macro avg     0.8178    0.8108    0.8111       160\n",
      "weighted avg     0.8169    0.8125    0.8115       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df45_edu = df45[df45['Flair']=='Education']\n",
    "target_labels = df45_edu['DS_Label'].values\n",
    "pred_labels = df45_edu['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7196    0.9390    0.8148        82\n",
      "           1     0.9057    0.6154    0.7328        78\n",
      "\n",
      "    accuracy                         0.7812       160\n",
      "   macro avg     0.8126    0.7772    0.7738       160\n",
      "weighted avg     0.8103    0.7812    0.7748       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df78_edu = df78[df78['Flair']=='Education']\n",
    "target_labels = df78_edu['DS_Label'].values\n",
    "pred_labels = df78_edu['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Career"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9085    0.8476    0.8770       164\n",
      "           1     0.7283    0.8272    0.7746        81\n",
      "\n",
      "    accuracy                         0.8408       245\n",
      "   macro avg     0.8184    0.8374    0.8258       245\n",
      "weighted avg     0.8489    0.8408    0.8431       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_career = df2[df2['Flair']=='Career']\n",
    "target_labels = df2_career['DS_Label'].values\n",
    "pred_labels = df2_career['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8820    0.8659    0.8738       164\n",
      "           1     0.7381    0.7654    0.7515        81\n",
      "\n",
      "    accuracy                         0.8327       245\n",
      "   macro avg     0.8100    0.8156    0.8127       245\n",
      "weighted avg     0.8344    0.8327    0.8334       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df13_career = df13[df13['Flair']=='Career']\n",
    "target_labels = df13_career['DS_Label'].values\n",
    "pred_labels = df13_career['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8817    0.9085    0.8949       164\n",
      "           1     0.8026    0.7531    0.7771        81\n",
      "\n",
      "    accuracy                         0.8571       245\n",
      "   macro avg     0.8421    0.8308    0.8360       245\n",
      "weighted avg     0.8555    0.8571    0.8559       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df20_career = df20[df20['Flair']=='Career']\n",
    "target_labels = df20_career['DS_Label'].values\n",
    "pred_labels = df20_career['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9007    0.8293    0.8635       164\n",
      "           1     0.7021    0.8148    0.7543        81\n",
      "\n",
      "    accuracy                         0.8245       245\n",
      "   macro avg     0.8014    0.8220    0.8089       245\n",
      "weighted avg     0.8350    0.8245    0.8274       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df45_career = df45[df45['Flair']=='Career']\n",
    "target_labels = df45_career['DS_Label'].values\n",
    "pred_labels = df45_career['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8779    0.9207    0.8988       164\n",
      "           1     0.8219    0.7407    0.7792        81\n",
      "\n",
      "    accuracy                         0.8612       245\n",
      "   macro avg     0.8499    0.8307    0.8390       245\n",
      "weighted avg     0.8594    0.8612    0.8593       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df78_career = df78[df78['Flair']=='Career']\n",
    "target_labels = df78_career['DS_Label'].values\n",
    "pred_labels = df78_career['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Life Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9196    0.8655    0.8918       119\n",
      "           1     0.7778    0.8615    0.8175        65\n",
      "\n",
      "    accuracy                         0.8641       184\n",
      "   macro avg     0.8487    0.8635    0.8546       184\n",
      "weighted avg     0.8695    0.8641    0.8655       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_lf = df2[df2['Flair']=='Life Decisions']\n",
    "target_labels = df2_lf['DS_Label'].values\n",
    "pred_labels = df2_lf['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9076    0.9076    0.9076       119\n",
      "           1     0.8308    0.8308    0.8308        65\n",
      "\n",
      "    accuracy                         0.8804       184\n",
      "   macro avg     0.8692    0.8692    0.8692       184\n",
      "weighted avg     0.8804    0.8804    0.8804       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df13_lf = df13[df13['Flair']=='Life Decisions']\n",
    "target_labels = df13_lf['DS_Label'].values\n",
    "pred_labels = df13_lf['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8952    0.9328    0.9136       119\n",
      "           1     0.8667    0.8000    0.8320        65\n",
      "\n",
      "    accuracy                         0.8859       184\n",
      "   macro avg     0.8809    0.8664    0.8728       184\n",
      "weighted avg     0.8851    0.8859    0.8848       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df20_lf = df20[df20['Flair']=='Life Decisions']\n",
    "target_labels = df20_lf['DS_Label'].values\n",
    "pred_labels = df20_lf['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9196    0.8655    0.8918       119\n",
      "           1     0.7778    0.8615    0.8175        65\n",
      "\n",
      "    accuracy                         0.8641       184\n",
      "   macro avg     0.8487    0.8635    0.8546       184\n",
      "weighted avg     0.8695    0.8641    0.8655       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df45_lf = df45[df45['Flair']=='Life Decisions']\n",
    "target_labels = df45_lf['DS_Label'].values\n",
    "pred_labels = df45_lf['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8880    0.9328    0.9098       119\n",
      "           1     0.8644    0.7846    0.8226        65\n",
      "\n",
      "    accuracy                         0.8804       184\n",
      "   macro avg     0.8762    0.8587    0.8662       184\n",
      "weighted avg     0.8797    0.8804    0.8790       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df78_lf = df78[df78['Flair']=='Life Decisions']\n",
    "target_labels = df78_lf['DS_Label'].values\n",
    "pred_labels = df78_lf['Pred_Label'].values\n",
    "\n",
    "\n",
    "print(classification_report(target_labels, pred_labels,labels=labels, \n",
    "                            target_names=target_names, digits=sigdig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
