{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicating SemEval Task 9 - Subtask A results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, accuracy_score as acc\n",
    "import numpy\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "from spellchecker import SpellChecker\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../SemEval_Task_9/Subtask-A-master/V1.4_Training.csv',\n",
    "                         header=None, names=['id','sentence','label'])\n",
    "dev_data = pd.read_csv('../SemEval_Task_9/Subtask-A-master/SubtaskA_Trial_Test_Labeled.csv', \n",
    "                       encoding='latin-1', header=0)\n",
    "test_data = pd.read_csv('../SemEval_Task_9/Subtask-A-master/SubtaskA_EvaluationData_labeled.csv',\n",
    "                        header=None, names=['id','sentence','label'])\n",
    "\n",
    "sent_list = train_data.loc[:, ['sentence']].values.tolist()\n",
    "gold_labels = train_data.loc[:,'label'].values.tolist()\n",
    "\n",
    "test_sent_list = test_data.loc[:, 'sentence'].values.tolist()\n",
    "test_gold_labels = test_data.loc[:,'label'].values.tolist()\n",
    "\n",
    "dev_sent_list = dev_data.loc[:, 'sentence'].values.tolist()\n",
    "dev_gold_labels = dev_data.loc[:,'label'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 is a suggestion, 0 is not.\n",
      "Distribution of Train set: Counter({0: 6415, 1: 2085})\n",
      "Distribution of Dev set: Counter({1: 296, 0: 296})\n",
      "Distribution of Test set: Counter({0: 746, 1: 87})\n"
     ]
    }
   ],
   "source": [
    "print(\"1 is a suggestion, 0 is not.\")\n",
    "print(\"Distribution of Train set:\", Counter(gold_labels))\n",
    "print(\"Distribution of Dev set:\", Counter(dev_gold_labels))\n",
    "print(\"Distribution of Test set:\", Counter(test_gold_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(sent_list):\n",
    "\n",
    "    keywords = [\"suggest\",\"recommend\",\"hopefully\",\"go for\",\"request\",\"it would be nice\",\"adding\",\n",
    "                \"should come with\",\"should be able\",\"could come with\", \"i need\" , \"we need\",\"needs\", \n",
    "                \"would like to\",\"would love to\",\"allow\",\"add\"]\n",
    "\n",
    "    # Goldberg et al.\n",
    "    pattern_strings = [r'.*would\\slike.*if.*', r'.*i\\swish.*', r'.*i\\shope.*', r'.*i\\swant.*', \n",
    "                       r'.*hopefully.*', r\".*if\\sonly.*\", r\".*would\\sbe\\sbetter\\sif.*\", r\".*should.*\", \n",
    "                       r\".*would\\sthat.*\",r\".*can't\\sbelieve.*didn't.*\", r\".*don't\\sbelieve.*didn't.*\", \n",
    "                       r\".*do\\swant.*\", r\".*i\\scan\\shas.*\"]\n",
    "\n",
    "    compiled_patterns = []\n",
    "    for patt in pattern_strings:\n",
    "        compiled_patterns.append(re.compile(patt))\n",
    "\n",
    "    label_list = []\n",
    "    for sent in sent_list:\n",
    "        tokenized_sent = word_tokenize(sent)\n",
    "        tagged_sent = nltk.pos_tag(tokenized_sent)\n",
    "        tags = [i[1] for i in tagged_sent]\n",
    "        label = 0\n",
    "        patt_matched = False\n",
    "        for compiled_patt in compiled_patterns:\n",
    "            joined_sent = \" \".join(tokenized_sent)\n",
    "            matches = compiled_patt.findall(joined_sent)\n",
    "            if len(matches) > 0:\n",
    "                patt_matched = True\n",
    "        keyword_match = any(elem in keywords for elem in tokenized_sent)\n",
    "\n",
    "\n",
    "        pos_match = any(elem in ['MD', 'VB'] for elem in tags)\n",
    "\n",
    "        if patt_matched:\n",
    "            label = 1\n",
    "        elif keyword_match == True:\n",
    "            label = 1\n",
    "        elif pos_match == True:\n",
    "            label = 1\n",
    "\n",
    "        label_list.append(label)\n",
    "\n",
    "\n",
    "\n",
    "    return label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline performance on test: 0.26755852842809363\n"
     ]
    }
   ],
   "source": [
    "test_pred_labels = classify(test_sent_list)\n",
    "print(\"Baseline performance on test:\", f1_score(test_gold_labels, test_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline performance on dev: 0.720626631853786\n"
     ]
    }
   ],
   "source": [
    "dev_pred_labels = classify(dev_sent_list)\n",
    "print(\"Baseline performance on dev:\", f1_score(dev_gold_labels, dev_pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some observations\n",
    "\n",
    "If the pos_match option is turned off in the baseline checker, F1 **goes up** to 0.38\n",
    "\n",
    "**89%** accuracy can be obtained simply by predicting the majority class -- not advice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NTUA-IS results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gr_classify(sent_list, sk, P_ab=True, P_c=True, imperative=True, spelling=False):\n",
    "    \n",
    "    # words from above with other example words they included - P_a\n",
    "    pattern_pa = [\"suggest\",\"recommend\",\"hopefully\",\"go for\",\"request\",\"it would be nice\",\"adding\",\n",
    "                   \"should come with\",\"should be able\",\"could come with\", \"i need\" , \"we need\",\"needs\", \n",
    "                   \"would like to\",\"would love to\",\"allow\",\"add\", \"helpful\", \"allow\", \"disallow\", \"idea\",\n",
    "                   \"consider\"]\n",
    "\n",
    "    # Goldberg et al.\n",
    "    pattern_pc = [r'.*would\\slike.*if.*', r'.*i\\swish.*', r'.*i\\shope.*', r'.*i\\swant.*', \n",
    "                  r'.*hopefully.*', r\".*if\\sonly.*\", r\".*would\\sbe\\sbetter\\sif.*\", r\".*should.*\",\n",
    "                  r\".*would\\sthat.*\", r\".*can't\\sbelieve.*didn't.*\", r\".*don't\\sbelieve.*didn't.*\", \n",
    "                  r\".*do\\swant.*\", r\".*i\\scan\\shas.*\"]\n",
    "    \n",
    "    # pattern list P_c rules for subtask A\n",
    "    pattern_pc += [r'.*should\\s(not|be|take|include|start).*', r'.*be\\sbetter.*', r'.*that\\sway.*',\n",
    "                   r'.*so\\sthat.*', r'.*why\\snot.*', r'.*suggestion\\sis.*', r'.*good\\ssolution.*',\n",
    "                   r'.*the\\sidea.*', r'.*to\\sallow.*', r'.*would\\smake.*', r'.*(will|would)\\sbe.*',\n",
    "                   r'.*(to|would|could)\\senable\\s(i|would|id)\\s(like|prefer).*', r'.*am\\sasking\\sfor.*',\n",
    "                   r'.*look\\sinto.*', r'.*make\\sit.*', r'.*at\\sleast.*', r'.*we\\sneed.*']\n",
    "    compiled_pc = [re.compile(patt) for patt in pattern_pc]\n",
    "    \n",
    "    # pattern list P_b rules for subtask B (and possibly the same for subtask A)\n",
    "    # pattern list P_b rules for subtask A\n",
    "    pattern_pb = [r'.*do\\snot.*', r'.*if\\sonly.*', r'.*(so|before|can|for|if)\\syou.*', \n",
    "                   r'.*you\\s(will|need|can|may).*', r'.*(make|be)\\ssure.*', r'.*watch\\sout.*', \n",
    "                   r'.*(go|going|asking|wishing)\\sfor.*', r'.*would\\sadvise.*', \n",
    "                   r'.*(will|would|could)\\sbe.*', r'.*be\\s(prepared|careful|warned|forewarned).*',\n",
    "                   r'.*(i/would/i\\'d)\\s(like|prefer).*', r'.*highly\\srecommended.*', \n",
    "                   r'.*(look|looking)\\s(into|for|up|around).*', r'.*why\\snot.*', r'.*is\\sthere.*',\n",
    "                   r'.*we\\sneed.*']\n",
    "    compiled_pb = [re.compile(patt) for patt in pattern_pb]\n",
    "        \n",
    "    pos_pattern_strings = [r'^UH\\sVBP.*', r'^MD\\sRB\\sPRP.*', r'^(VB|VBP).*', r'^MD.*', \n",
    "                           r'^(DT|RB|PRP|NN)\\sVB.*']\n",
    "    compiled_pos_patterns = [re.compile(patt) for patt in pos_pattern_strings]\n",
    "\n",
    "\n",
    "    label_list = []\n",
    "    for sent in sent_list:\n",
    "        score = 0\n",
    "        \n",
    "        if len(sent.split()) < 5:\n",
    "            score -=0.2\n",
    "        \n",
    "        clause_split = [a for a in re.split(\"[.,!?;]|(Please|please)\", sent) if a not in [None, '', ' ', 'Please', 'please']]\n",
    "        for clause in clause_split:\n",
    "            clause_pos = TextBlob(clause).tags\n",
    "            \n",
    "            words = [i[0] for i in clause_pos]\n",
    "            tags = [i[1] for i in clause_pos]\n",
    "            \n",
    "            # Correct misspells\n",
    "            if spelling:\n",
    "                words = [spell.correction(w) if w not in spell else w for w in words]\n",
    "            \n",
    "            if P_ab:            \n",
    "                # Pattern P_a\n",
    "                if any(elem in pattern_pa for elem in words):\n",
    "                    score += 0.3\n",
    "\n",
    "                # Pattern P_b\n",
    "                for compiled_patt in compiled_pb:\n",
    "                    joined_sent = \" \".join(words)\n",
    "                    matches = compiled_patt.findall(joined_sent)\n",
    "                    if len(matches) > 0:\n",
    "                        score += 0.1\n",
    "            if P_c:\n",
    "                # Pattern P_c\n",
    "                for compiled_patt in compiled_pc:\n",
    "                    joined_sent = \" \".join(words)\n",
    "                    matches = compiled_patt.findall(joined_sent)\n",
    "                    if len(matches) > 0:\n",
    "                        score += 0.25\n",
    "\n",
    "            if imperative:\n",
    "                # Imperative POS pattern check\n",
    "                for compiled_pos_patt in compiled_pos_patterns:\n",
    "                    joined_sent = \" \".join(tags)\n",
    "                    matches = compiled_pos_patt.findall(joined_sent)\n",
    "                    if len(matches) > 0:\n",
    "                        score += sk\n",
    "\n",
    "        if score > 0.15:\n",
    "            label_list.append(1)\n",
    "        else:\n",
    "            label_list.append(0)\n",
    "\n",
    "    return label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing - lower case, spell check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "929\n"
     ]
    }
   ],
   "source": [
    "sent_list = [a[0].lower() for a in sent_list]\n",
    "test_sent_list = [a.lower() for a in test_sent_list]\n",
    "dev_sent_list = [a.lower() for a in dev_sent_list]\n",
    "\n",
    "misspell = 0\n",
    "spell = SpellChecker()\n",
    "spell.word_frequency.load_words([a for a in string.punctuation] + ['titles/subtitles', 'upload', 'simd'])\n",
    "for sent in test_sent_list:\n",
    "    for word in word_tokenize(sent):\n",
    "        if word in spell:\n",
    "            continue\n",
    "        else:\n",
    "#             print(word)\n",
    "            misspell += 1\n",
    "            \n",
    "print(misspell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTUA-IS rules performance on test: 0.3234624145785877\n"
     ]
    }
   ],
   "source": [
    "test_pred_labels = gr_classify(test_sent_list, sk=0.25)\n",
    "print(\"NTUA-IS rules performance on test:\", f1_score(test_gold_labels, test_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTUA-IS rules performance on dev: 0.7147239263803681\n"
     ]
    }
   ],
   "source": [
    "dev_pred_labels = gr_classify(dev_sent_list, sk=0.25)\n",
    "print(\"NTUA-IS rules performance on dev:\", f1_score(dev_gold_labels, dev_pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P_ab performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTUA-IS rules performance on test with p_ab: 0.3647798742138364\n"
     ]
    }
   ],
   "source": [
    "test_pred_labels = gr_classify(test_sent_list, sk=0.0, P_ab=True, P_c=False, imperative=False)\n",
    "print(\"NTUA-IS rules performance on test with p_ab:\", f1_score(test_gold_labels, test_pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P_c performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTUA-IS rules performance on test with p_c: 0.44086021505376344\n"
     ]
    }
   ],
   "source": [
    "test_pred_labels = gr_classify(test_sent_list, sk=0.0, P_ab=False, P_c=True, imperative=False)\n",
    "print(\"NTUA-IS rules performance on test with p_c:\", f1_score(test_gold_labels, test_pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imperative performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTUA-IS rules performance on test with imperative: 0.19760479041916168\n"
     ]
    }
   ],
   "source": [
    "test_pred_labels = gr_classify(test_sent_list, sk=0.18, P_ab=False, P_c=False, imperative=True)\n",
    "print(\"NTUA-IS rules performance on test with imperative:\", f1_score(test_gold_labels, test_pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask B Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_b = pd.read_csv('../SemEval_Task_9/Subtask-B-master/V1.4_Training.csv',\n",
    "                         header=None, names=['id','sentence','label'])\n",
    "dev_data_b = pd.read_csv('../SemEval_Task_9/Subtask-B-master/SubtaskB_Trial_Test_Labeled.csv', \n",
    "                       encoding='latin-1', header=0)\n",
    "test_data_b = pd.read_csv('../SemEval_Task_9/Subtask-B-master/SubtaskB_EvaluationData_labeled.csv',\n",
    "                        header=None, names=['id','sentence','label'])\n",
    "\n",
    "sent_list_b = train_data_b.loc[:, ['sentence']].values.tolist()\n",
    "gold_labels_b = train_data_b.loc[:,'label'].values.tolist()\n",
    "\n",
    "test_sent_list_b = test_data_b.loc[:, 'sentence'].values.tolist()\n",
    "test_gold_labels_b = test_data_b.loc[:,'label'].values.tolist()\n",
    "\n",
    "dev_sent_list_b = dev_data_b.loc[:, 'sentence'].values.tolist()\n",
    "dev_gold_labels_b = dev_data_b.loc[:,'label'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 is a suggestion, 0 is not.\n",
      "Distribution of Train set: Counter({0: 6415, 1: 2085})\n",
      "Distribution of Dev set: Counter({1: 404, 0: 404})\n",
      "Distribution of Test set: Counter({0: 476, 1: 348})\n"
     ]
    }
   ],
   "source": [
    "print(\"1 is a suggestion, 0 is not.\")\n",
    "print(\"Distribution of Train set:\", Counter(gold_labels_b))\n",
    "print(\"Distribution of Dev set:\", Counter(dev_gold_labels_b))\n",
    "print(\"Distribution of Test set:\", Counter(test_gold_labels_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline performance on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline performance on test: 0.7321668909825034\n"
     ]
    }
   ],
   "source": [
    "test_pred_labels_b = classify(test_sent_list_b)\n",
    "print(\"Baseline performance on test:\", f1_score(test_gold_labels_b, test_pred_labels_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gr_classify_b(sent_list, sk, P_a=True, P_b=True, imperative=True, spelling=False):\n",
    "    \n",
    "    # words from above with other example words they included - P_a\n",
    "#     keywords_pa = [\"suggest\",\"recommend\",\"hopefully\",\"go for\",\"request\",\"it would be nice\",\"adding\",\n",
    "#                    \"should come with\",\"should be able\",\"could come with\", \"i need\" , \"we need\",\"needs\", \n",
    "#                    \"would like to\",\"would love to\",\"allow\",\"add\", \"helpful\", \"allow\", \"disallow\", \"idea\",\n",
    "#                    \"consider\"]\n",
    "    pattern_pa = ['avoid', 'beware', \"don't\", 'expect', 'remember', 'tip', 'advise', 'advice', 'recommended',\n",
    "                  'recommendation', 'suggest', 'suggestion', 'ask', 'bring', 'pick', 'consider', 'spend', \n",
    "                  'expect', 'can', 'please', 'can', 'hopefully', 'enjoying', 'want', 'wanting', 'prefer']\n",
    "    \n",
    "\n",
    "#     # Goldberg et al.\n",
    "#     pattern_pc = [r'.*would\\slike.*if.*', r'.*i\\swish.*', r'.*i\\shope.*', r'.*i\\swant.*', \n",
    "#                   r'.*hopefully.*', r\".*if\\sonly.*\", r\".*would\\sbe\\sbetter\\sif.*\", r\".*should.*\",\n",
    "#                   r\".*would\\sthat.*\", r\".*can't\\sbelieve.*didn't.*\", r\".*don't\\sbelieve.*didn't.*\", \n",
    "#                   r\".*do\\swant.*\", r\".*i\\scan\\shas.*\"]\n",
    "    \n",
    "#     # pattern list P_c rules for subtask A\n",
    "#     pattern_pc += [r'.*should\\s(not|be|take|include|start).*', r'.*be\\sbetter.*', r'.*that\\sway.*',\n",
    "#                    r'.*so\\sthat.*', r'.*why\\snot.*', r'.*suggestion\\sis.*', r'.*good\\ssolution.*',\n",
    "#                    r'.*the\\sidea.*', r'.*to\\sallow.*', r'.*would\\smake.*', r'.*(will|would)\\sbe.*',\n",
    "#                    r'.*(to|would|could)\\senable\\s(i|would|id)\\s(like|prefer).*', r'.*am\\sasking\\sfor.*',\n",
    "#                    r'.*look\\sinto.*', r'.*make\\sit.*', r'.*at\\sleast.*', r'.*we\\sneed.*']\n",
    "#     compiled_pc = [re.compile(patt) for patt in pattern_pc]\n",
    "    \n",
    "    # pattern list P_b rules for subtask B (and possibly the same for subtask A)\n",
    "    # pattern list P_b rules for subtask A\n",
    "    pattern_pb = [r'.*do\\snot.*', r'.*if\\sonly.*', r'.*(so|before|can|for|if)\\syou.*', \n",
    "                   r'.*you\\s(will|need|can|may).*', r'.*(make|be)\\ssure.*', r'.*watch\\sout.*', \n",
    "                   r'.*(go|going|asking|wishing)\\sfor.*', r'.*would\\sadvise.*', \n",
    "                   r'.*(will|would|could)\\sbe.*', r'.*be\\s(prepared|careful|warned|forewarned).*',\n",
    "                   r'.*(i/would/i\\'d)\\s(like|prefer).*', r'.*highly\\srecommended.*', \n",
    "                   r'.*(look|looking)\\s(into|for|up|around).*', r'.*why\\snot.*', r'.*is\\sthere.*',\n",
    "                   r'.*we\\sneed.*']\n",
    "    compiled_pb = [re.compile(patt) for patt in pattern_pb]\n",
    "        \n",
    "    pos_pattern_strings = [r'^UH\\sVBP.*', r'^MD\\sRB\\sPRP.*', r'^(VB|VBP).*', r'^MD.*', \n",
    "                           r'^(DT|RB|PRP|NN)\\sVB.*']\n",
    "    compiled_pos_patterns = [re.compile(patt) for patt in pos_pattern_strings]\n",
    "\n",
    "\n",
    "    label_list = []\n",
    "    for sent in sent_list:\n",
    "        score = 0\n",
    "        \n",
    "        if len(sent.split()) < 5:\n",
    "            score -=0.2\n",
    "        \n",
    "        clause_split = [a for a in re.split(\"[.,!?;]|(please)\", sent) if a not in \n",
    "                        [None, '', ' ', 'please']]\n",
    "        for clause in clause_split:\n",
    "            clause_pos = TextBlob(clause).tags\n",
    "            \n",
    "            words = [i[0] for i in clause_pos]\n",
    "            tags = [i[1] for i in clause_pos]\n",
    "            \n",
    "            # Correct misspells\n",
    "            if spelling:\n",
    "                words = [spell.correction(w) if w not in spell else w for w in words]\n",
    "            \n",
    "            if P_a:            \n",
    "                # Pattern P_a\n",
    "                if any(elem in pattern_pa for elem in words):\n",
    "                    score += 0.25\n",
    "\n",
    "\n",
    "            if P_b:\n",
    "                # Pattern P_b\n",
    "                for compiled_patt in compiled_pb:\n",
    "                    joined_sent = \" \".join(words)\n",
    "                    matches = compiled_patt.findall(joined_sent)\n",
    "                    if len(matches) > 0:\n",
    "                        score += 0.25\n",
    "\n",
    "            if imperative:\n",
    "                # Imperative POS pattern check\n",
    "                for compiled_pos_patt in compiled_pos_patterns:\n",
    "                    joined_sent = \" \".join(tags)\n",
    "                    matches = compiled_pos_patt.findall(joined_sent)\n",
    "                    if len(matches) > 0:\n",
    "                        score += sk\n",
    "\n",
    "        if score > 0.15:\n",
    "            label_list.append(1)\n",
    "        else:\n",
    "            label_list.append(0)\n",
    "\n",
    "    return label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing - lower case, spell check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_list_b = [a[0].lower() for a in sent_list_b]\n",
    "test_sent_list_b = [a.lower() for a in test_sent_list_b]\n",
    "dev_sent_list_b = [a.lower() for a in dev_sent_list_b]\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "import string\n",
    "\n",
    "spell = SpellChecker(distance=1)\n",
    "spell.word_frequency.load_words([a for a in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTUA-IS rules performance on test: 0.7296849087893864\n"
     ]
    }
   ],
   "source": [
    "test_pred_labels_b = gr_classify_b(test_sent_list_b, sk=0)\n",
    "print(\"NTUA-IS rules performance on test:\", f1_score(test_gold_labels_b, test_pred_labels_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTUA-IS rules performance on dev: 0.6313131313131313\n"
     ]
    }
   ],
   "source": [
    "dev_pred_labels_b = gr_classify_b(dev_sent_list_b, sk=0.25)\n",
    "print(\"NTUA-IS rules performance on dev:\", f1_score(dev_gold_labels_b, dev_pred_labels_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P_a performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTUA-IS rules performance on test with P_a: 0.4968944099378882\n"
     ]
    }
   ],
   "source": [
    "test_pred_labels_b = gr_classify_b(test_sent_list_b, sk=0.0, P_a=True, P_b=False, imperative=False)\n",
    "print(\"NTUA-IS rules performance on test with P_a:\", f1_score(test_gold_labels_b, test_pred_labels_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P_b performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTUA-IS rules performance on test with P_b: 0.2035623409669211\n"
     ]
    }
   ],
   "source": [
    "test_pred_labels_b = gr_classify_b(test_sent_list_b, sk=0.0, P_a=False, P_b=True, imperative=False)\n",
    "print(\"NTUA-IS rules performance on test with P_b:\", f1_score(test_gold_labels_b, test_pred_labels_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imperative performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTUA-IS rules performance on test with imperative: 0.038674033149171276\n"
     ]
    }
   ],
   "source": [
    "test_pred_labels_b = gr_classify_b(test_sent_list_b, sk=0.15, P_a=False, P_b=False, imperative=True)\n",
    "print(\"NTUA-IS rules performance on test with imperative:\", f1_score(test_gold_labels_b, test_pred_labels_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With spell correction on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTUA-IS rules performance on test: 0.5625\n"
     ]
    }
   ],
   "source": [
    "test_pred_labels_b = gr_classify_b(test_sent_list_b, sk=0.0, spelling=True)\n",
    "print(\"NTUA-IS rules performance on test:\", f1_score(test_gold_labels_b, test_pred_labels_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
